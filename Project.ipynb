{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4cd184d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured model: gemini-1.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DA_CSI01\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Load API key from environment or .env file\n",
    "load_dotenv()  # reads .env if present\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Chưa có GOOGLE_API_KEY trong biến môi trường hoặc file .env\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "MODEL_NAME = \"gemini-1.5-flash\" #model\n",
    "\n",
    "model = genai.GenerativeModel(MODEL_NAME)\n",
    "print(\"Configured model:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70641672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('user', 'Xin chào, bạn là ai?'), ('assistant', 'Mình là FruitBot, mình giúp bạn về các loại trái cây.'), ('user', 'Chuối chín thì ăn như nào ngon?')]\n"
     ]
    }
   ],
   "source": [
    "# Multi-turn helper: giữ tối đa `max_turns` lượt (mỗi lượt = user + assistant)\n",
    "from collections import deque\n",
    "\n",
    "class MultiTurnChat:\n",
    "    def __init__(self, system_prompt=None):\n",
    "        self.history = []\n",
    "        if system_prompt:\n",
    "            self.history.append({\n",
    "                \"role\": \"system\",\n",
    "                \"parts\": [{\"text\": system_prompt}]\n",
    "            })\n",
    "\n",
    "    def add_user(self, text):\n",
    "        self.history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [{\"text\": text}]\n",
    "        })\n",
    "\n",
    "    def add_assistant(self, text):\n",
    "        self.history.append({\n",
    "            \"role\": \"model\",\n",
    "            \"parts\": [{\"text\": text}]\n",
    "        })\n",
    "\n",
    "    def as_generative_input(self):\n",
    "        return self.history\n",
    "\n",
    "# Demo\n",
    "chat = MultiTurnChat(max_turns=2)\n",
    "chat.add_user('Xin chào, bạn là ai?')\n",
    "chat.add_assistant('Mình là FruitBot, mình giúp bạn về các loại trái cây.')\n",
    "chat.add_user('Chuối chín thì ăn như nào ngon?')\n",
    "print(chat.get_history_messages())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c660f815",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['role', 'content']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bot_text\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Quick interactive demo in notebook\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[43mask_fruitbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMón trái cây nào nhiều vitamin C nhất?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFruitBOT:\u001b[39m\u001b[38;5;124m'\u001b[39m, reply)\n",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m, in \u001b[0;36mask_fruitbot\u001b[1;34m(chat, user_text, model_obj, temperature, max_output_tokens)\u001b[0m\n\u001b[0;32m      6\u001b[0m messages \u001b[38;5;241m=\u001b[39m chat\u001b[38;5;241m.\u001b[39mas_generative_input()  \u001b[38;5;66;03m# giả sử trả về list các dict hoặc string\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Call genai to generate a response\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_output_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m bot_text \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(resp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(resp)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Save assistant's reply into history\u001b[39;00m\n",
      "File \u001b[1;32md:\\DA_CSI01\\.venv\\lib\\site-packages\\google\\generativeai\\generative_models.py:305\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contents:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents must not be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 305\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mcontents \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m request\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrole:\n\u001b[0;32m    314\u001b[0m     request\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m=\u001b[39m _USER_ROLE\n",
      "File \u001b[1;32md:\\DA_CSI01\\.venv\\lib\\site-packages\\google\\generativeai\\generative_models.py:154\u001b[0m, in \u001b[0;36mGenerativeModel._prepare_request\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     tool_config \u001b[38;5;241m=\u001b[39m content_types\u001b[38;5;241m.\u001b[39mto_tool_config(tool_config)\n\u001b[1;32m--> 154\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[43mcontent_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m generation_types\u001b[38;5;241m.\u001b[39mto_generation_config_dict(generation_config)\n\u001b[0;32m    157\u001b[0m merged_gc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generation_config\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32md:\\DA_CSI01\\.venv\\lib\\site-packages\\google\\generativeai\\types\\content_types.py:326\u001b[0m, in \u001b[0;36mto_contents\u001b[1;34m(contents)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(contents, Iterable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(contents, (\u001b[38;5;28mstr\u001b[39m, Mapping)):\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;66;03m# strict_to_content so [[parts], [parts]] doesn't assume roles.\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m         contents \u001b[38;5;241m=\u001b[39m [strict_to_content(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m contents]\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m contents\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;66;03m# If you get a TypeError here it's probably because that was a list\u001b[39;00m\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;66;03m# of parts, not a list of contents, so fall back to `to_content`.\u001b[39;00m\n",
      "File \u001b[1;32md:\\DA_CSI01\\.venv\\lib\\site-packages\\google\\generativeai\\types\\content_types.py:326\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(contents, Iterable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(contents, (\u001b[38;5;28mstr\u001b[39m, Mapping)):\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;66;03m# strict_to_content so [[parts], [parts]] doesn't assume roles.\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m         contents \u001b[38;5;241m=\u001b[39m [\u001b[43mstrict_to_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m contents]\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m contents\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;66;03m# If you get a TypeError here it's probably because that was a list\u001b[39;00m\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;66;03m# of parts, not a list of contents, so fall back to `to_content`.\u001b[39;00m\n",
      "File \u001b[1;32md:\\DA_CSI01\\.venv\\lib\\site-packages\\google\\generativeai\\types\\content_types.py:304\u001b[0m, in \u001b[0;36mstrict_to_content\u001b[1;34m(content)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstrict_to_content\u001b[39m(content: StrictContentType):\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, Mapping):\n\u001b[1;32m--> 304\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, protos\u001b[38;5;241m.\u001b[39mContent):\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m content\n",
      "File \u001b[1;32md:\\DA_CSI01\\.venv\\lib\\site-packages\\google\\generativeai\\types\\content_types.py:176\u001b[0m, in \u001b[0;36m_convert_dict\u001b[1;34m(d)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m protos\u001b[38;5;241m.\u001b[39mBlob(blob)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to determine the intended type of the `dict`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor `Content`, a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key is expected. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor `Part`, either an \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline_data\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key is expected. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor `Blob`, both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmime_type\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keys are expected. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHowever, the provided dictionary has the following keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(d\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to determine the intended type of the `dict`. For `Content`, a 'parts' key is expected. For `Part`, either an 'inline_data' or a 'text' key is expected. For `Blob`, both 'mime_type' and 'data' keys are expected. However, the provided dictionary has the following keys: ['role', 'content']\""
     ]
    }
   ],
   "source": [
    "# Tạo mô hình Gemini với system prompt\n",
    "def ask_fruitbot(chat: MultiTurnChat, user_text: str, model_obj=model, temperature: float = 0.2, max_output_tokens: int = 256):\n",
    "    # Add user message to history\n",
    "    chat.add_user(user_text)\n",
    "    # Build messages array\n",
    "    messages = chat.as_generative_input()  # giả sử trả về list các dict hoặc string\n",
    "\n",
    "    # Call genai to generate a response\n",
    "    resp = model_obj.generate_content(\n",
    "        contents=messages,\n",
    "        generation_config={\n",
    "            \"temperature\": temperature,\n",
    "            \"max_output_tokens\": max_output_tokens\n",
    "        }\n",
    "    )\n",
    "    bot_text = resp.text if hasattr(resp, 'text') else str(resp)\n",
    "    # Save assistant's reply into history\n",
    "    chat.add_assistant(bot_text)\n",
    "    return bot_text\n",
    "\n",
    "# Quick interactive demo in notebook\n",
    "reply = ask_fruitbot(chat, \"Món trái cây nào nhiều vitamin C nhất?\")\n",
    "print('FruitBOT:', reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe7c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhoBot sẵn sàng hỗ trợ. Gõ 'exit' để thoát.\n",
      "\n",
      "PhoBot: Chào bạn! Có gì mình giúp được không?\n",
      "\n",
      "PhoBot: Mình là FruitBot, trợ lý AI giúp bạn tìm hiểu về trái cây.\n",
      "\n",
      "PhoBot: Trái cây là phần quả của thực vật, thường có vị ngọt và chứa nhiều chất dinh dưỡng.\n",
      "\n",
      "PhoBot: Có gì mình có thể giúp bạn?\n",
      "\n",
      "PhoBot: Bạn có câu hỏi nào về trái cây không?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bạn có thể lưu lịch sử chat vào file JSON nếu muốn persist giữa các lần chạy\n",
    "import json\n",
    "\n",
    "def save_history(chat: MultiTurnChat, path: str = 'chat_history.json'):\n",
    "    data = chat.get_history_messages()\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_history(path: str = 'chat_history.json') -> MultiTurnChat:\n",
    "    c = MultiTurnChat(max_turns=2)\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        for role, text in data:\n",
    "            if role == 'user':\n",
    "                c.add_user(text)\n",
    "            else:\n",
    "                c.add_assistant(text)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6148f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv da_csi01)",
   "language": "python",
   "name": "da_csi01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
